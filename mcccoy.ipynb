{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/mccoy.png\" align=\"left\" width=100/>\n",
    "\n",
    "---\n",
    "--- \n",
    "# MCCOY\n",
    "## Millimiter Characterization of Complex Organics in Young stellar objects\n",
    "--- \n",
    "---\n",
    "#### Written and updated by Carlos E. MuÃ±oz-Romero (2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynesty\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sig\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Times\"\n",
    "\n",
    "from dynesty import plotting as dyplot\n",
    "from dynesty import utils as dyfunc\n",
    "from numpy import random\n",
    "\n",
    "from lmfit import Model, Parameters\n",
    "from scipy.stats import norm, truncnorm\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''APPLY REDSHIFT TO SPECTRA'''\n",
    "def redshift(spectrum, velocity):\n",
    "    z = np.sqrt( (1 + (velocity/c)) / (1 - (velocity/c)) ) - 1\n",
    "    return spectrum/(1+z)\n",
    "\n",
    "'''CONVERT FREQUENCY TO VELOCITY IN KM/S'''\n",
    "def freq_to_vel(spectrum, reference_frequency):\n",
    "    return (np.array((c*reference_frequency - c*spectrum) / reference_frequency) )/1000\n",
    "\n",
    "'''IDENTIFY EMISSION LINES'''\n",
    "def identify(frequencies, velocities, intensities, catalog, dis=0.2):\n",
    "    \n",
    "    peaks = sig.find_peaks(intensities)[0]\n",
    "    peak_intensities = intensities[peaks]\n",
    "    peak_frequencies = frequencies[peaks]\n",
    "    \n",
    "    # TAKE ONLY PEAKS ABOVE 5 SIGMA\n",
    "    peak_frequencies = peak_frequencies[peak_intensities>=5*rms]\n",
    "    peak_intensities = peak_intensities[peak_intensities>=5*rms]\n",
    "    peak_velocities = freq_to_vel(peak_frequencies, reference_frequency)\n",
    "\n",
    "    detection = dict({\"frequencies\":[], \n",
    "                      \"velocities\":[], \n",
    "                      \"catalog_frequencies\":[],\n",
    "                      \"eup\":[],\n",
    "                      \"Smu2\":[],\n",
    "                      \"gu\":[],\n",
    "                      \"logaij\":[],\n",
    "                      \"transition\":[]})\n",
    "    \n",
    "    for i,peak in enumerate(peak_frequencies):\n",
    "        for j,line in enumerate(catalog[\"frequencies\"]):\n",
    "            if abs(peak-line)<=dis:# and \"F\" not in catalog[\"transition\"][j]:\n",
    "                detection[\"frequencies\"].append(peak_frequencies[i])\n",
    "                detection[\"velocities\"].append(peak_velocities[i])\n",
    "                detection[\"catalog_frequencies\"].append(catalog[\"frequencies\"][j])\n",
    "                detection[\"eup\"].append(catalog[\"eup\"][j])\n",
    "                detection[\"gu\"].append(catalog[\"gu\"][j])\n",
    "                detection[\"logaij\"].append(catalog[\"logaij\"][j])\n",
    "                detection[\"Smu2\"].append(catalog[\"Smu2\"][j])\n",
    "                detection[\"transition\"].append(catalog[\"transition\"][j])\n",
    "                \n",
    "    return detection\n",
    "\n",
    "'GENERATE SPECTRAL WINDOWS AROUND EACH DETECTED TRANSITION'\n",
    "def generate_windows(velocities, intensities, detections):\n",
    "    windows = []\n",
    "\n",
    "    for det_velocity in detections[\"velocities\"]:\n",
    "        window = dict({\"velocities\":[],\n",
    "                       \"intensities\":[]})\n",
    "        v = velocities[abs(velocities-det_velocity)<window_size]\n",
    "        i = intensities[abs(velocities-det_velocity)<window_size]\n",
    "        window[\"velocities\"] = v-det_velocity\n",
    "        window[\"intensities\"] = i\n",
    "        windows.append(window)\n",
    "        \n",
    "    return windows\n",
    "\n",
    "'IDENTIFY POINTS WHICH MAKE UP THE EMISSION LINE'\n",
    "\n",
    "# Pick all monotonically decreasing neighbors of each detected transition as a line to fit.\n",
    "def idlines(windows, detections):\n",
    "    lines = []\n",
    "    for i,window in enumerate(windows):\n",
    "        neighbors = dict({\"velocities\":[],\n",
    "                          \"intensities\":[],\n",
    "                          \"indices\":[],\n",
    "                          \"line_idx\":0})\n",
    "        line_idx = np.where(window[\"velocities\"]+detections[\"velocities\"][i] == detections[\"velocities\"][i])[0][0]\n",
    "        neighbors['line_idx'] = line_idx\n",
    "        # Left neighbors\n",
    "        diff = 0\n",
    "        i = 1\n",
    "        current = line_idx\n",
    "        while diff <= 0 and abs(window[\"velocities\"][current-i])<line_FWHM*5:\n",
    "            current = line_idx-i\n",
    "            neighbors[\"velocities\"].append(window[\"velocities\"][current])\n",
    "            neighbors[\"intensities\"].append(window[\"intensities\"][current])\n",
    "            neighbors[\"indices\"].append(current)\n",
    "            diff = window[\"intensities\"][current-1]-window[\"intensities\"][current]\n",
    "            i+=1\n",
    "        # Right neighbors\n",
    "        diff = 0\n",
    "        i = 0\n",
    "        current = line_idx\n",
    "        while diff <= 0 and abs(window[\"velocities\"][current+i])<line_FWHM*5:\n",
    "            current = line_idx+i\n",
    "            neighbors[\"velocities\"].append(window[\"velocities\"][current])\n",
    "            neighbors[\"intensities\"].append(window[\"intensities\"][current])\n",
    "            neighbors[\"indices\"].append(current)\n",
    "            diff = window[\"intensities\"][current+1]-window[\"intensities\"][current]\n",
    "            i+=1\n",
    "        lines.append(neighbors)\n",
    "    return lines\n",
    "\n",
    "def gaussian(x, amp, center, fwhm):\n",
    "    sigma = fwhm/(2*np.sqrt(2*np.log(2)))\n",
    "    return amp / (np.sqrt(2*np.pi) * sigma) * np.exp(-(x-center)**2 / (2*(sigma**2)))\n",
    "\n",
    "def polynomial_2d(x, m, b, z):\n",
    "    return z*x**2 + m*x + b\n",
    "\n",
    "def emission_line_fitter(x, amp, center, fwhm, m, b, z):\n",
    "    return gaussian(x, amp, center, fwhm)*is_line + polynomial_2d(x, m, b, z)*use_baseline\n",
    "\n",
    "def emission_line(x, amp, center, fwhm, m, b, z):\n",
    "    return gaussian(x, amp, center, fwhm) + polynomial_2d(x, m, b, z)\n",
    "\n",
    "def emission_lmfit(x, y, is_line):\n",
    "    \n",
    "    emission_y = y*is_line\n",
    "    gmodel = Model(emission_line_fitter)\n",
    "    params = Parameters()\n",
    "    params.add_many(('amp', 0.025, True, 0, 1, None, None),\n",
    "                    ('center', 0, False, -1, 1, None, None),\n",
    "                    ('fwhm', 0.5, True, 0.1, 3, None, None),\n",
    "                    ('m', 0, True, -1, 1, None, None),\n",
    "                    ('z', 0, True, -1, 1, None, None),\n",
    "                    ('b', 0, True, -0.02, 0.1, None, None))\n",
    "    \n",
    "    result = gmodel.fit(y, params, x=x)\n",
    "    return result\n",
    "\n",
    "def get_tau(nugu, detections, T):\n",
    "    c_cgs = c*100\n",
    "    widths_cgs = widths*100000\n",
    "    nupper = nugu*np.array(detections[\"gu\"])\n",
    "    aij = 10**np.array(detections[\"logaij\"])\n",
    "    freqs_cgs = np.array(detections[\"catalog_frequencies\"])*1e6\n",
    "    \n",
    "    tau = np.sqrt(4*np.log(2)/np.pi) * (nupper*aij*c_cgs**3)/(widths_cgs*8*np.pi*freqs_cgs**3)\n",
    "    tau = tau * (np.exp(h*freqs_cgs / (k*T)) - 1)\n",
    "    return tau \n",
    "\n",
    "def rotdiag(x, log10Ntot, T):\n",
    "    \n",
    "    tau = get_tau(nugu, detections, T)\n",
    "    Ntot = 10**log10Ntot\n",
    "    C = tau / (1 - np.exp(-tau))\n",
    "    partitionf = Q(T)\n",
    "   \n",
    "    if partitionf < 1:\n",
    "        partitionf = 1\n",
    "        \n",
    "    #C = np.array([c if c>0 else 0.0001 for c in C])\n",
    "    return np.log(Ntot) - np.log(partitionf) - np.log(C) - (1/T)*x\n",
    "\n",
    "def rotdiag_lmfit(x, y):\n",
    "    \n",
    "    rmodel = Model(rotdiag)\n",
    "    params = Parameters()\n",
    "    params.add_many(('log10Ntot', 14, True, 8, 16, None, None),\n",
    "                    ('T', 20, True, 1, 150, None, None))\n",
    "    #emcee_kws = dict(steps=100000, burn=30000, thin=10)\n",
    "    result = rmodel.fit(y, params, x=x)#, fit_kws=emcee_kws)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User input\n",
    "The pipeline is compatible with tab-separated spectroscopy files generated by the NRAO splatalogue database, with frequency in MHz. (https://www.cv.nrao.edu/php/splat/). It is necessary to add extra columns to this file to estimate the rotational partition function via interpolation, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'SPLATALOGUE FILE'\n",
    "molecule_name = \"CH3C3N\"\n",
    "catalog_file = \"./splatalogue/CH3C3N_catalog.tsv\"\n",
    "spectrum_file = \"./181_WSW_FTS200_3mm_average_data_Tmb.dat\"\n",
    "reference_frequency = 93750.7299 \n",
    "'ESTIMATE OF FULL WIDTH AT HALF MAXIMUM OF EMISSION LINES IN [km/s]'\n",
    "line_FWHM = 0.5\n",
    "'VELOCITY OF THE SOURCE IN [km/s]'\n",
    "v_lsr = 0\n",
    "'ROOT MEAN SQUARE OF INTENSITY DATA IN [K]'\n",
    "rms = 5e-3\n",
    "'SIZE OF SPECTRAL WINDOW TO USE AROUND EACH DETECTED TRANSITION IN [km/s]'\n",
    "window_size = 20\n",
    "'CONSTANTS'\n",
    "c =  2.998*1e8 # m/s\n",
    "k = 1.3807 * 1e-16 # erg/K \n",
    "h = 6.62607 * 1e-27 # erg s\n",
    "toHz = 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and transform to velocity units (km/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = np.loadtxt(spectrum_file)\n",
    "frequencies = redshift(spectrum[:,0], v_lsr)\n",
    "velocities = freq_to_vel(frequencies, reference_frequency)\n",
    "intensities = spectrum[:,1]\n",
    "catalog_dataframe = pd.read_csv(catalog_file, delimiter=\"\\t\", header=0, index_col=False)\n",
    "catalog = dict({\"frequencies\":catalog_dataframe[\"Freq-MHz(rest frame,redshifted)\"], \n",
    "                \"velocities\":freq_to_vel(catalog_dataframe[\"Freq-MHz(rest frame,redshifted)\"], reference_frequency),\n",
    "                \"Smu2\":catalog_dataframe[\"S<sub>ij</sub>&#956;<sup>2</sup> (D<sup>2</sup>)\"],\n",
    "                \"eup\":catalog_dataframe[\"E_U (K)\"],\n",
    "                \"gu\":catalog_dataframe[\"Upper State Degeneracy\"],\n",
    "                \"logaij\":catalog_dataframe[\"Log<sub>10</sub> (A<sub>ij</sub>)\"],\n",
    "                \"transition\":catalog_dataframe[\"Resolved QNs\"],\n",
    "                \"Qrot\":catalog_dataframe[\"Q\"],\n",
    "                \"Trot\":catalog_dataframe[\"T\"],\n",
    "                \"linelist\":catalog_dataframe[\"Linelist\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all emission lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequencies': [86754.291],\n",
       " 'velocities': [22373.504552522954],\n",
       " 'catalog_frequencies': [86754.171],\n",
       " 'eup': [75.75089],\n",
       " 'Smu2': [938.97955],\n",
       " 'gu': [86.0],\n",
       " 'logaij': [-4.08104],\n",
       " 'transition': ['21(2)-20(2)']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections = identify(frequencies, velocities, intensities, catalog, dis=0.2)\n",
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define spectral windows and center around zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "windows = generate_windows(velocities, intensities, detections)\n",
    "lines = idlines(windows, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in windows:\n",
    "    plt.figure()\n",
    "    plt.step(window[\"velocities\"], window[\"intensities\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform initial fit of emission lines via non-linear least-squares minimization. Then, estimate uncertainties via nested sampling of the posterior distribution, using truncated normal priors centered around the lmfit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike(theta):\n",
    "    amp, fwhm, lnf = theta\n",
    "    m = lmfit_m\n",
    "    b = lmfit_b\n",
    "    z = lmfit_z\n",
    "    center = 0 \n",
    "   \n",
    "    model = emission_line(x, amp, center, fwhm, m, b, z)\n",
    "    inv_sigma2 = 1.0 / (yerr**2 + model**2 * np.exp(2 * lnf))\n",
    "    return -0.5 * (np.sum((y-model)**2 * inv_sigma2 - np.log(inv_sigma2)))\n",
    "\n",
    "line_results_dynesty = []\n",
    "line_results_lmfit = []\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    is_line = np.zeros(len(windows[i][\"velocities\"]))\n",
    "    is_line[lines[i][\"indices\"]] = 1\n",
    "\n",
    "    x = windows[i][\"velocities\"]\n",
    "    y = windows[i][\"intensities\"]\n",
    "    \n",
    "    use_baseline = (y<3*rms).astype(int)\n",
    "    \n",
    "    lmfit_result = emission_lmfit(x, y, is_line)\n",
    "    line_results_lmfit.append(lmfit_result)\n",
    "    \n",
    "    lmfit_amp = lmfit_result.best_values[\"amp\"]\n",
    "    lmfit_center = lmfit_result.best_values[\"center\"]\n",
    "    lmfit_fwhm = lmfit_result.best_values[\"fwhm\"]\n",
    "    lmfit_m = lmfit_result.best_values[\"m\"]\n",
    "    lmfit_b = lmfit_result.best_values[\"b\"]\n",
    "    lmfit_z = lmfit_result.best_values[\"z\"]\n",
    "    \n",
    "    x = x[is_line==1]\n",
    "    y = y[is_line==1]\n",
    "    y = [k if k>0 else 0 for k in y]\n",
    "    yerr = random.randn(len(y))*0.001\n",
    "    \n",
    "    def prior_transform(utheta):\n",
    "        uamp, ufwhm, ulnf = utheta\n",
    "        # Truncated Normal\n",
    "        mean_amp , s_amp  = lmfit_amp, 0.3*lmfit_amp  # mean and standard deviation\n",
    "        low_amp , high_amp  = 0, 2*lmfit_amp  \n",
    "        low_n_amp, high_n_amp = (low_amp - mean_amp ) / s_amp , (high_amp - s_amp ) / s_amp  # standardize\n",
    "        amp = truncnorm.ppf(uamp, low_n_amp, high_n_amp, loc=mean_amp, scale=s_amp)\n",
    "        # Truncated Normal\n",
    "        mean_fwhm , s_fwhm  = lmfit_fwhm, 0.3*lmfit_fwhm  # mean and standard deviation\n",
    "        low_fwhm , high_fwhm  = 0, 3\n",
    "        low_n_fwhm, high_n_fwhm = (low_fwhm - mean_fwhm ) / s_fwhm , (high_fwhm - s_fwhm ) / s_fwhm  # standardize\n",
    "        fwhm = truncnorm.ppf(ufwhm, low_n_fwhm, high_n_fwhm, loc=mean_fwhm, scale=s_fwhm)\n",
    "        \n",
    "        lnf = 15. * ulnf - 10.\n",
    "        return amp, fwhm, lnf\n",
    "    \n",
    "    dsampler = dynesty.DynamicNestedSampler(loglike, prior_transform, ndim=3,\n",
    "                                            bound='single', sample='auto')\n",
    "    dsampler.run_nested(dlogz_init=0.01)\n",
    "    dres = dsampler.results\n",
    "    line_results_dynesty.append(dres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = []    \n",
    "widths = []    \n",
    "\n",
    "flux_errors = []\n",
    "widths_errors = []\n",
    "\n",
    "for i,dres in enumerate(line_results_dynesty):\n",
    "    \n",
    "    x = windows[i][\"velocities\"]\n",
    "    y = windows[i][\"intensities\"]\n",
    "    \n",
    "    is_line = np.zeros(len(windows[i][\"velocities\"]))\n",
    "    is_line[lines[i][\"indices\"]] = 1\n",
    "    \n",
    "    # Extract sampling results.\n",
    "    samples = dres.samples  # samples\n",
    "    weights = np.exp(dres.logwt - dres.logz[-1])  # normalized weights\n",
    "    \n",
    "    lmfit_result = line_results_lmfit[i]\n",
    "    lmfit_amp = lmfit_result.best_values[\"amp\"]\n",
    "    lmfit_center = lmfit_result.best_values[\"center\"]\n",
    "    lmfit_fwhm = lmfit_result.best_values[\"fwhm\"]\n",
    "    lmfit_m = lmfit_result.best_values[\"m\"]\n",
    "    lmfit_b = lmfit_result.best_values[\"b\"]\n",
    "    lmfit_z = lmfit_result.best_values[\"z\"]\n",
    "    \n",
    "    # Compute quantiles.\n",
    "    quantiles = [dyfunc.quantile(samps, [0.1586, 0.5, 0.84135], weights=weights)\n",
    "                 for samps in samples.T]\n",
    "    \n",
    "    dynesty_flux = quantiles[0][1]\n",
    "    dynesty_fwhm = quantiles[1][1]\n",
    "    \n",
    "    fluxes.append(dynesty_flux)\n",
    "    widths.append(dynesty_fwhm)\n",
    "    flux_errors.append([dynesty_flux-quantiles[0][0], quantiles[0][2]-dynesty_flux])\n",
    "    widths_errors.append([dynesty_fwhm-quantiles[1][0], quantiles[1][2]-dynesty_fwhm])\n",
    "    \n",
    "    plt.figure()\n",
    "    window_linspace = np.linspace(min(windows[i][\"velocities\"]), max(windows[i][\"velocities\"]),10000)\n",
    "    #plt.step(x, y, color=\"gray\")\n",
    "    plt.step(x, y-polynomial_2d(x,lmfit_m,lmfit_b,lmfit_z), color=\"black\")\n",
    "    #plt.scatter(x,y*is_line)\n",
    "    #plt.plot(window_linspace, emission_line(window_linspace, lmfit_amp,\n",
    "                                        #lmfit_center, lmfit_fwhm, lmfit_m, lmfit_b, lmfit_z),color=\"red\")\n",
    "    plt.plot(window_linspace, emission_line(window_linspace, dynesty_flux,\n",
    "                                        lmfit_center, dynesty_fwhm, lmfit_m, lmfit_b, lmfit_z),color=\"green\")\n",
    "    print(max(y*is_line)/(5e-3))\n",
    "    \n",
    "    plt.xlabel(\"km/s\")\n",
    "    plt.ylabel(\"K\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r'$\\int T dv$ ', r'FWHM ',r'$\\ln f$']\n",
    "for dres in line_results_dynesty:    \n",
    "    #fig, axes = dyplot.traceplot(dres, labels=labels, title_fmt=(\".4f\"),\n",
    "                                 #trace_cmap='inferno', post_color=\"black\", label_kwargs=dict({\"fontsize\":15}))\n",
    "    fig, axes = dyplot.cornerplot(dres, color='dodgerblue', show_titles=True, title_fmt=(\".4f\"), labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strengths = np.array(detections[\"Smu2\"]) * (1e-18)**2 # from D^2 to (statC cm)^2\n",
    "fluxes = np.array(fluxes)\n",
    "fluxes_cgs = fluxes*100000 # in cm/s\n",
    "widths = np.array(widths)\n",
    "flux_errors = np.array(flux_errors).reshape(len(lines),2)\n",
    "flux_errors_cgs = np.array(flux_errors).reshape(len(lines),2)*100000 \n",
    "widths_errors = np.array(widths_errors).reshape(len(lines),2)\n",
    "# Upper-level populations Nu/gu\n",
    "nugu = (3*k*fluxes_cgs)/(8*(np.pi**3)*np.array(detections[\"catalog_frequencies\"])*toHz*strengths)\n",
    "lnnugu = np.log(nugu)\n",
    "lnnugu_err = flux_errors / np.array([[f,f] for f in fluxes]).reshape(len(lines),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_array = catalog[\"Qrot\"]\n",
    "T_array  = catalog[\"Trot\"]\n",
    "Q_array = Q_array[Q_array == Q_array]\n",
    "T_array = T_array[T_array == T_array]\n",
    "\n",
    "'FIT A POLYNOMIAL TO THE PARTITION FUNCTION DATA TO INTERPOLATE'\n",
    "Qfit = np.polyfit(T_array, Q_array, 3)\n",
    "Q = np.poly1d(Qfit)\n",
    "\n",
    "x = np.array(detections[\"eup\"])\n",
    "y = lnnugu\n",
    "yerr = lnnugu_err.T \n",
    "\n",
    "lmfit_result = rotdiag_lmfit(x, y)    \n",
    "lmfit_T = lmfit_result.best_values[\"T\"]\n",
    "lmfit_log10Ntot = lmfit_result.best_values[\"log10Ntot\"]\n",
    "lmfit_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-likelihood\n",
    "def loglike(theta):\n",
    "    \n",
    "    T, log10Ntot, lnf = theta\n",
    "    \n",
    "    model = rotdiag(x,log10Ntot,T)\n",
    "    inv_sigma2 = 1.0 / (yerr**2 + model**2 * np.exp(2 * lnf))\n",
    "    return -0.5 * (np.sum((y-model)**2 * inv_sigma2 - np.log(inv_sigma2)))\n",
    "\n",
    "# prior transform\n",
    "def prior_transform(utheta):\n",
    "    uT, ulog10Ntot, ulnf = utheta\n",
    "    \n",
    "    # Truncated Normal\n",
    "    #mean_T , s_T  = lmfit_T, 0.5*lmfit_T  # mean and standard deviation\n",
    "    #low_T , high_T  = 1, 2*lmfit_T\n",
    "    #low_n_T, high_n_T = (low_T - mean_T ) / s_T , (high_T - s_T ) / s_T  # standardize\n",
    "    #T = truncnorm.ppf(uT, low_n_T, high_n_T, loc=mean_T, scale=s_T)\n",
    "    # Truncated Normal\n",
    "    #mean_log10Ntot , s_log10Ntot  = lmfit_log10Ntot, 0.5*lmfit_log10Ntot  # mean and standard deviation\n",
    "    #low_log10Ntot , high_log10Ntot  = 8, 1.5*lmfit_log10Ntot\n",
    "    #low_n_log10Ntot, high_n_log10Ntot = (low_log10Ntot - mean_log10Ntot ) / s_log10Ntot , (high_log10Ntot - s_log10Ntot ) / s_log10Ntot  # standardize\n",
    "    #log10Ntot = truncnorm.ppf(ulog10Ntot, low_n_log10Ntot, high_n_log10Ntot, loc=mean_log10Ntot, scale=s_log10Ntot)\n",
    "   \n",
    "    T = uT*150+1\n",
    "    log10Ntot = ulog10Ntot*12+8\n",
    "    lnf = 31 * ulnf - 30.\n",
    "    return T, log10Ntot, lnf\n",
    "\n",
    "dsampler = dynesty.DynamicNestedSampler(loglike, prior_transform, ndim=3, bound='multi', sample='auto')\n",
    "dsampler.run_nested(dlogz_init=0.01)\n",
    "rotdiag_res = dsampler.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sampling results.\n",
    "samples = rotdiag_res.samples  # samples\n",
    "weights = np.exp(rotdiag_res.logwt - rotdiag_res.logz[-1])  # normalized weights\n",
    "quantiles = [dyfunc.quantile(samps, [0.025, 0.1586, 0.5, 0.84135, 0.975], weights=weights)\n",
    "                 for samps in samples.T]\n",
    "\n",
    "#labels = [r'T$_{rot}$ ', r'log$_{10}$(N$_{tot}$)', r'$\\ln(f)$']\n",
    "labels = [r'T$_{rot}$', r'log$_{10}$(N$_{tot}$)', 'lnf']\n",
    "#span = [[0,20],[7,15],[0,1.1],[0,1.1],[0,1.1],[0,1.1]]\n",
    "fig, axes = dyplot.cornerplot(rotdiag_res, color='dodgerblue', show_titles=True, dims=[0,1],\n",
    "                              title_fmt=(\".3f\"), quantiles = [0.1586, 0.5, 0.84135], span=[0.95,0.98],\n",
    "                              labels=labels, label_kwargs=dict({\"fontsize\":15}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x,y,yerr=lnnugu_err.T, fmt=\"o\",color=\"black\",capsize=4)\n",
    "alphas = weights/max(weights)*0.1\n",
    "eulinspace = np.linspace(0,max(x)+10)\n",
    "sorted_x = np.array(sorted(list(x)))\n",
    "\n",
    "for i,sample in enumerate(rotdiag_res.samples[::10]):\n",
    "    plt.plot(sorted_x, rotdiag(sorted_x, sample[1], sample[0]),alpha=0.1,color=\"dodgerblue\", linewidth=0.05)\n",
    "plt.plot(sorted_x, rotdiag(sorted_x, quantiles[1][2], quantiles[0][2]),\n",
    "         color=\"black\",linestyle=\"--\",linewidth=2)\n",
    "\n",
    "plt.ylabel('log(N$_{u}$/g$_{u})$', fontsize=15)\n",
    "plt.xlabel('E$_u$', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = get_tau(nugu, detections, 58)\n",
    "Ntot = 10**11\n",
    "C = tau / (1 - np.exp(-tau))\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tau(nugu, detections, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotdiagfile = open(\"./fits/{}_rotdiag\".format(molecule_name), \"wb\")\n",
    "pickle.dump(rotdiag_res, rotdiagfile)\n",
    "rotdiagfile.close()\n",
    "\n",
    "linesfile = open(\"./fits/{}_lines\".format(molecule_name), \"wb\")\n",
    "pickle.dump(line_results_dynesty, linesfile)\n",
    "linesfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectionsfile = open(\"./fits/{}_detections\".format(molecule_name), \"wb\")\n",
    "pickle.dump(detections, detectionsfile)\n",
    "detectionsfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogfile = open(\"./fits/{}_catalog\".format(molecule_name), \"wb\")\n",
    "pickle.dump(catalog, catalogfile)\n",
    "catalogfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
