{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "--- \n",
    "# MCCOY\n",
    "## Millimiter Characterization of Complex Organics in Young stellar objects\n",
    "--- \n",
    "---\n",
    "#### Written and updated by Carlos E. MuÃ±oz-Romero (2020)\n",
    "![caption](imgs/mccoy.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynesty\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sig\n",
    "\n",
    "from dynesty import plotting as dyplot\n",
    "from dynesty import utils as dyfunc\n",
    "from numpy import random\n",
    "\n",
    "from lmfit import Model, Parameters\n",
    "from scipy.stats import norm, truncnorm\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''APPLY REDSHIFT TO SPECTRA'''\n",
    "def redshift(spectrum, velocity):\n",
    "    z = np.sqrt( (1 + (velocity/c)) / (1 - (velocity/c)) ) - 1\n",
    "    return spectrum/(1+z)\n",
    "\n",
    "'''CONVERT FREQUENCY TO VELOCITY IN KM/S'''\n",
    "def freq_to_vel(spectrum, reference_frequency):\n",
    "    return (np.array((c*reference_frequency - c*spectrum) / reference_frequency) )/1000\n",
    "\n",
    "'''IDENTIFY EMISSION LINES'''\n",
    "def identify(frequencies, velocities, intensities, catalog):\n",
    "    \n",
    "    peaks = sig.find_peaks(intensities)[0]\n",
    "    peak_intensities = intensities[peaks]\n",
    "    peak_frequencies = frequencies[peaks]\n",
    "    \n",
    "    # TAKE ONLY PEAKS ABOVE 5 SIGMA\n",
    "    peak_frequencies = peak_frequencies[peak_intensities>=5*rms]\n",
    "    peak_intensities = peak_intensities[peak_intensities>=5*rms]\n",
    "    peak_velocities = freq_to_vel(peak_frequencies, reference_frequency)\n",
    "\n",
    "    detection = dict({\"frequencies\":[], \n",
    "                      \"velocities\":[], \n",
    "                      \"catalog_frequencies\":[],\n",
    "                      \"eup\":[],\n",
    "                      \"Smu2\":[],\n",
    "                      \"logaij\":[],\n",
    "                      \"transition\":[]})\n",
    "    \n",
    "    for i,peak in enumerate(peak_frequencies):\n",
    "        for j,line in enumerate(catalog[\"frequencies\"]):\n",
    "            if abs(peak-line)<=0.2 and \"F\" not in catalog[\"transition\"][j]:\n",
    "                detection[\"frequencies\"].append(peak_frequencies[i])\n",
    "                detection[\"velocities\"].append(peak_velocities[i])\n",
    "                detection[\"catalog_frequencies\"].append(catalog[\"frequencies\"][j])\n",
    "                detection[\"eup\"].append(catalog[\"eup\"][j])\n",
    "                detection[\"logaij\"].append(catalog[\"logaij\"][j])\n",
    "                detection[\"Smu2\"].append(catalog[\"Smu2\"][j])\n",
    "                detection[\"transition\"].append(catalog[\"transition\"][j])\n",
    "                \n",
    "    return detection\n",
    "\n",
    "'GENERATE SPECTRAL WINDOWS AROUND EACH DETECTED TRANSITION'\n",
    "def generate_windows(velocities, intensities, detections):\n",
    "    windows = []\n",
    "\n",
    "    for det_velocity in detections[\"velocities\"]:\n",
    "        window = dict({\"velocities\":[],\n",
    "                       \"intensities\":[]})\n",
    "        v = velocities[abs(velocities-det_velocity)<window_size]\n",
    "        i = intensities[abs(velocities-det_velocity)<window_size]\n",
    "        window[\"velocities\"] = v-det_velocity\n",
    "        window[\"intensities\"] = i\n",
    "        windows.append(window)\n",
    "        \n",
    "    return windows\n",
    "\n",
    "'IDENTIFY POINTS WHICH MAKE UP THE EMISSION LINE'\n",
    "\n",
    "# Pick all monotonically decreasing neighbors of each detected transition as a line to fit.\n",
    "def idlines(windows, detections):\n",
    "    lines = []\n",
    "    for i,window in enumerate(windows):\n",
    "        neighbors = dict({\"velocities\":[],\n",
    "                          \"intensities\":[],\n",
    "                          \"indices\":[],\n",
    "                          \"line_idx\":0})\n",
    "        line_idx = np.where(window[\"velocities\"]+detections[\"velocities\"][i] == detections[\"velocities\"][i])[0][0]\n",
    "        neighbors['line_idx'] = line_idx\n",
    "        # Left neighbors\n",
    "        diff = 0\n",
    "        i = 1\n",
    "        current = line_idx\n",
    "        while diff <= 0 and abs(window[\"velocities\"][current-i])<line_FWHM*5:\n",
    "            current = line_idx-i\n",
    "            neighbors[\"velocities\"].append(window[\"velocities\"][current])\n",
    "            neighbors[\"intensities\"].append(window[\"intensities\"][current])\n",
    "            neighbors[\"indices\"].append(current)\n",
    "            diff = window[\"intensities\"][current-1]-window[\"intensities\"][current]\n",
    "            i+=1\n",
    "        # Right neighbors\n",
    "        diff = 0\n",
    "        i = 0\n",
    "        current = line_idx\n",
    "        while diff <= 0 and abs(window[\"velocities\"][current+i])<line_FWHM*5:\n",
    "            current = line_idx+i\n",
    "            neighbors[\"velocities\"].append(window[\"velocities\"][current])\n",
    "            neighbors[\"intensities\"].append(window[\"intensities\"][current])\n",
    "            neighbors[\"indices\"].append(current)\n",
    "            diff = window[\"intensities\"][current+1]-window[\"intensities\"][current]\n",
    "            i+=1\n",
    "        lines.append(neighbors)\n",
    "    return lines\n",
    "\n",
    "def gaussian(x, amp, center, fwhm):\n",
    "    sigma = fwhm/(2*np.sqrt(2*np.log(2)))\n",
    "    return amp / (np.sqrt(2*np.pi) * sigma) * np.exp(-(x-center)**2 / (2*(sigma**2)))\n",
    "\n",
    "def polynomial_1d(x, m, b):\n",
    "    return m*x + b\n",
    "\n",
    "def emission_line_fitter(x, amp, center, fwhm, m, b):\n",
    "    return gaussian(x, amp, center, fwhm)*is_line + polynomial_1d(x, m, b)\n",
    "\n",
    "def emission_line(x, amp, center, fwhm, m, b):\n",
    "    return gaussian(x, amp, center, fwhm) + polynomial_1d(x, m, b)\n",
    "\n",
    "def emission_lmfit(x, y, is_line):\n",
    "    \n",
    "    emission_y = y*is_line\n",
    "    gmodel = Model(emission_line_fitter)\n",
    "    params = Parameters()\n",
    "    params.add_many(('amp', 0.025, True, 0, 1, None, None),\n",
    "                    ('center', 0, False, -1, 1, None, None),\n",
    "                    ('fwhm', 0.5, True, 0, 3, None, None),\n",
    "                    ('m', 0, True, -1, 1, None, None),\n",
    "                    ('b', 0, True, -0.02, 0.1, None, None))\n",
    "    \n",
    "    result = gmodel.fit(y, params, x=x)\n",
    "    return result\n",
    "\n",
    "def rotdiag(x, log10Ntot, T, tau):\n",
    "    Ntot = 10**log10Ntot\n",
    "    C = tau / (1 - np.exp(-tau))\n",
    "    return np.log(Ntot) - np.log(Q(T)) - np.log(C) - (1/T)*x\n",
    "\n",
    "def rotdiag_lmfit(x, y):\n",
    "    \n",
    "    rmodel = Model(rotdiag)\n",
    "    params = Parameters()\n",
    "    params.add_many(('log10Ntot', 13, True, 8, 14, None, None),\n",
    "                    ('T', 20, True, 1, 150, None, None),\n",
    "                    ('tau', 1e-4, True, 1e-10, 1, None, None))\n",
    "    \n",
    "    result = rmodel.fit(y, params, x=x)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User input\n",
    "The pipeline is compatible with tab-separated spectroscopy files generated by the NRAO splatalogue database, with frequency in MHz. (https://www.cv.nrao.edu/php/splat/). It is necessary to add extra columns to this file to estimate the rotational partition function via interpolation, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'SPLATALOGUE FILE'\n",
    "molecule_name = \"CH3CN\"\n",
    "catalog_file = \"./splatalogue/CH3CN_catalog.tsv\"\n",
    "spectrum_file = \"./181_WSW_FTS200_3mm_average_data_Tmb.dat\"\n",
    "reference_frequency = 93750.7299 \n",
    "'ESTIMATE OF FULL WIDTH AT HALF MAXIMUM OF EMISSION LINES IN [km/s]'\n",
    "line_FWHM = 0.5\n",
    "'VELOCITY OF THE SOURCE IN [km/s]'\n",
    "v_lsr = 0\n",
    "'ROOT MEAN SQUARE OF INTENSITY DATA IN [K]'\n",
    "rms = 5e-3\n",
    "'SIZE OF SPECTRAL WINDOW TO USE AROUND EACH DETECTED TRANSITION IN [km/s]'\n",
    "window_size = 25\n",
    "'CONSTANTS'\n",
    "c =  2.998*1e8 # m/s\n",
    "k = 1.3807 * 1e-16 # erg/K\n",
    "toHz = 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and transform to velocity units (km/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = np.loadtxt(spectrum_file)\n",
    "frequencies = redshift(spectrum[:,0], v_lsr)\n",
    "velocities = freq_to_vel(frequencies, reference_frequency)\n",
    "intensities = spectrum[:,1]\n",
    "catalog_dataframe = pd.read_csv(catalog_file, delimiter=\"\\t\", header=0, index_col=False)\n",
    "catalog = dict({\"frequencies\":catalog_dataframe[\"Freq-MHz(rest frame,redshifted)\"], \n",
    "                \"velocities\":freq_to_vel(catalog_dataframe[\"Freq-MHz(rest frame,redshifted)\"], reference_frequency),\n",
    "                \"Smu2\":catalog_dataframe[\"S<sub>ij</sub>&#956;<sup>2</sup> (D<sup>2</sup>)\"],\n",
    "                \"eup\":catalog_dataframe[\"E_U (K)\"],\n",
    "                \"logaij\":catalog_dataframe[\"Log<sub>10</sub> (A<sub>ij</sub>)\"],\n",
    "                \"transition\":catalog_dataframe[\"Resolved QNs\"],\n",
    "                \"Qrot\":catalog_dataframe[\"Q\"],\n",
    "                \"Trot\":catalog_dataframe[\"T\"],\n",
    "                \"linelist\":catalog_dataframe[\"Linelist\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all emission lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = identify(frequencies, velocities, intensities, catalog)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define spectral windows and center around zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = generate_windows(velocities, intensities, detections)\n",
    "lines = idlines(windows, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in windows:\n",
    "    plt.figure()\n",
    "    plt.step(window[\"velocities\"], window[\"intensities\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform initial fit of emission lines via non-linear least-squares minimization. Then, estimate uncertainties via nested sampling of the posterior distribution, using truncated normal priors centered around the lmfit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22391it [05:42, 65.43it/s, batch: 14 | bound: 22 | nc: 1 | ncall: 218967 | eff(%): 10.226 | loglstar:  8.967 < 17.306 < 16.923 | logz: 13.975 +/-  0.074 | stop:  0.871]           \n",
      "19047it [03:55, 80.90it/s, batch: 10 | bound: 28 | nc: 16 | ncall: 168396 | eff(%): 11.311 | loglstar: 19.571 < 21.574 < 21.226 | logz: 17.629 +/-  0.078 | stop:  0.883]          \n",
      "19259it [04:21, 73.61it/s, batch: 11 | bound: 25 | nc: 17 | ncall: 187929 | eff(%): 10.248 | loglstar: 19.950 < 22.197 < 21.784 | logz: 18.680 +/-  0.076 | stop:  0.914]       \n",
      "18910it [03:56, 80.11it/s, batch: 10 | bound: 26 | nc: 4 | ncall: 171511 | eff(%): 11.026 | loglstar: 19.549 < 21.647 < 21.229 | logz: 17.651 +/-  0.078 | stop:  0.939]           \n",
      "21117it [04:28, 78.63it/s, batch: 11 | bound: 30 | nc: 17 | ncall: 193126 | eff(%): 10.934 | loglstar: 24.458 < 27.109 < 26.558 | logz: 23.139 +/-  0.073 | stop:  0.992]       \n",
      "19128it [03:48, 83.75it/s, batch: 10 | bound: 26 | nc: 5 | ncall: 166363 | eff(%): 11.498 | loglstar: 23.825 < 26.047 < 25.448 | logz: 22.091 +/-  0.077 | stop:  0.969]           \n"
     ]
    }
   ],
   "source": [
    "def loglike(theta):\n",
    "    amp, fwhm, lnf = theta\n",
    "    m = lmfit_m\n",
    "    b = lmfit_b\n",
    "    center = 0 \n",
    "   \n",
    "    model = emission_line(x, amp, center, fwhm, m, b)\n",
    "    inv_sigma2 = 1.0 / (yerr**2 + model**2 * np.exp(2 * lnf))\n",
    "    return -0.5 * (np.sum((y-model)**2 * inv_sigma2 - np.log(inv_sigma2)))\n",
    "\n",
    "line_results_dynesty = []\n",
    "line_results_lmfit = []\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    is_line = np.zeros(len(windows[i][\"velocities\"]))\n",
    "    is_line[lines[i][\"indices\"]] = 1\n",
    "\n",
    "    x = windows[i][\"velocities\"]\n",
    "    y = windows[i][\"intensities\"]\n",
    "\n",
    "    lmfit_result = emission_lmfit(x, y, is_line)\n",
    "    line_results_lmfit.append(lmfit_result)\n",
    "    \n",
    "    lmfit_amp = lmfit_result.best_values[\"amp\"]\n",
    "    lmfit_center = lmfit_result.best_values[\"center\"]\n",
    "    lmfit_fwhm = lmfit_result.best_values[\"fwhm\"]\n",
    "    lmfit_m = lmfit_result.best_values[\"m\"]\n",
    "    lmfit_b = lmfit_result.best_values[\"b\"]\n",
    "    \n",
    "    x = x[is_line==1]\n",
    "    y = y[is_line==1]\n",
    "    y = [k if k>0 else 0 for k in y]\n",
    "    yerr = random.randn(len(y))*0.001\n",
    "    \n",
    "    def prior_transform(utheta):\n",
    "        uamp, ufwhm, ulnf = utheta\n",
    "        # Truncated Normal\n",
    "        mean_amp , s_amp  = lmfit_amp, 0.2*lmfit_amp  # mean and standard deviation\n",
    "        low_amp , high_amp  = 0, 2*lmfit_amp  \n",
    "        low_n_amp, high_n_amp = (low_amp - mean_amp ) / s_amp , (high_amp - s_amp ) / s_amp  # standardize\n",
    "        amp = truncnorm.ppf(uamp, low_n_amp, high_n_amp, loc=mean_amp, scale=s_amp)\n",
    "        # Truncated Normal\n",
    "        mean_fwhm , s_fwhm  = lmfit_fwhm, 0.2*lmfit_fwhm  # mean and standard deviation\n",
    "        low_fwhm , high_fwhm  = 0, 2*lmfit_fwhm\n",
    "        low_n_fwhm, high_n_fwhm = (low_fwhm - mean_fwhm ) / s_fwhm , (high_fwhm - s_fwhm ) / s_fwhm  # standardize\n",
    "        fwhm = truncnorm.ppf(ufwhm, low_n_fwhm, high_n_fwhm, loc=mean_fwhm, scale=s_fwhm)\n",
    "        \n",
    "        lnf = 15. * ulnf - 10.\n",
    "        return amp, fwhm, lnf\n",
    "    \n",
    "    dsampler = dynesty.DynamicNestedSampler(loglike, prior_transform, ndim=3,\n",
    "                                            bound='multi', sample='auto')\n",
    "    dsampler.run_nested(dlogz_init=0.01)\n",
    "    dres = dsampler.results\n",
    "    line_results_dynesty.append(dres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = []    \n",
    "widths = []    \n",
    "\n",
    "flux_errors = []\n",
    "widths_errors = []\n",
    "\n",
    "for i,dres in enumerate(line_results_dynesty):\n",
    "    \n",
    "    x = windows[i][\"velocities\"]\n",
    "    y = windows[i][\"intensities\"]\n",
    "    # Extract sampling results.\n",
    "    samples = dres.samples  # samples\n",
    "    weights = np.exp(dres.logwt - dres.logz[-1])  # normalized weights\n",
    "    \n",
    "    lmfit_result = line_results_lmfit[i]\n",
    "    lmfit_amp = lmfit_result.best_values[\"amp\"]\n",
    "    lmfit_center = lmfit_result.best_values[\"center\"]\n",
    "    lmfit_fwhm = lmfit_result.best_values[\"fwhm\"]\n",
    "    lmfit_m = lmfit_result.best_values[\"m\"]\n",
    "    lmfit_b = lmfit_result.best_values[\"b\"]\n",
    "    \n",
    "    \n",
    "    # Compute quantiles.\n",
    "    quantiles = [dyfunc.quantile(samps, [0.1586, 0.5, 0.84135], weights=weights)\n",
    "                 for samps in samples.T]\n",
    "    \n",
    "    dynesty_flux = quantiles[0][1]\n",
    "    dynesty_fwhm = quantiles[1][1]\n",
    "    \n",
    "    fluxes.append(dynesty_flux)\n",
    "    widths.append(dynesty_fwhm)\n",
    "    flux_errors.append([dynesty_flux-quantiles[0][0], quantiles[0][2]-dynesty_flux])\n",
    "    widths_errors.append([dynesty_fwhm-quantiles[1][0], quantiles[1][2]-dynesty_fwhm])\n",
    "    \n",
    "    plt.figure()\n",
    "    window_linspace = np.linspace(min(windows[i][\"velocities\"]), max(windows[i][\"velocities\"]),10000)\n",
    "    plt.step(x, y, color=\"gray\")\n",
    "    \n",
    "    plt.plot(window_linspace, emission_line(window_linspace, lmfit_amp,\n",
    "                                        lmfit_center, lmfit_fwhm, lmfit_m, lmfit_b),color=\"red\")\n",
    "    plt.plot(window_linspace, emission_line(window_linspace, dynesty_flux,\n",
    "                                        lmfit_center, dynesty_fwhm, lmfit_m, lmfit_b),color=\"green\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r'$\\int T dv$ ', r'FWHM ',r'$\\ln f$']\n",
    "for dres in line_results_dynesty:    \n",
    "    #fig, axes = dyplot.traceplot(dres, labels=labels, title_fmt=(\".4f\"),\n",
    "                                 #trace_cmap='inferno', post_color=\"black\", label_kwargs=dict({\"fontsize\":15}))\n",
    "    fig, axes = dyplot.cornerplot(dres, color='dodgerblue', show_titles=True, title_fmt=(\".4f\"), labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "strengths = np.array(detections[\"Smu2\"]) * (1e-18)**2 # from D^2 to (statC cm)^2\n",
    "fluxes = np.array(fluxes)\n",
    "fluxes_cgs = fluxes*100000 # in cm/s\n",
    "widths = np.array(widths)\n",
    "flux_errors = np.array(flux_errors).reshape(len(lines),2)\n",
    "flux_errors_cgs = np.array(flux_errors).reshape(6,2)*100000 \n",
    "widths_errors = np.array(widths_errors).reshape(6,2)\n",
    "# Upper-level populations Nu/gu\n",
    "nugu = (3*k*fluxes_cgs)/(8*(np.pi**3)*np.array(detections[\"catalog_frequencies\"])*toHz*strengths)\n",
    "lnnugu = np.log(nugu)\n",
    "lnnugu_err = flux_errors / np.array([[f,f] for f in fluxes]).reshape(len(lines),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2> Model</h2> Model(rotdiag) <h2>Fit Statistics</h2><table><tr><td>fitting method</td><td>leastsq</td><td></td></tr><tr><td># function evals</td><td>34</td><td></td></tr><tr><td># data points</td><td>6</td><td></td></tr><tr><td># variables</td><td>3</td><td></td></tr><tr><td>chi-square</td><td> 0.61328885</td><td></td></tr><tr><td>reduced chi-square</td><td> 0.20442962</td><td></td></tr><tr><td>Akaike info crit.</td><td>-7.68407227</td><td></td></tr><tr><td>Bayesian info crit.</td><td>-8.30879386</td><td></td></tr></table><h2>Variables</h2><table><tr><th> name </th><th> value </th><th> standard error </th><th> relative error </th><th> initial value </th><th> min </th><th> max </th><th> vary </th></tr><tr><td> log10Ntot </td><td>  11.6183744 </td><td>  7251562.07 </td><td> (62414601.26%) </td><td> 13 </td><td>  8.00000000 </td><td>  14.0000000 </td><td> True </td></tr><tr><td> T </td><td>  13.2781291 </td><td>  6.09282003 </td><td> (45.89%) </td><td> 20 </td><td>  1.00000000 </td><td>  150.000000 </td><td> True </td></tr><tr><td> tau </td><td>  0.64622855 </td><td>  37394518.2 </td><td> (5786577849.28%) </td><td> 0.0001 </td><td>  1.0000e-10 </td><td>  1.00000000 </td><td> True </td></tr></table><h2>Correlations (unreported correlations are < 0.100)</h2><table><tr><td>log10Ntot</td><td>tau</td><td>1.0000</td></tr></table>"
      ],
      "text/plain": [
       "<lmfit.model.ModelResult at 0x1a3b0bf6a0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_array = catalog[\"Qrot\"]\n",
    "T_array  = catalog[\"Trot\"]\n",
    "Q_array = Q_array[Q_array == Q_array]\n",
    "T_array = T_array[T_array == T_array]\n",
    "\n",
    "'FIT A POLYNOMIAL TO THE PARTITION FUNCTION DATA TO INTERPOLATE'\n",
    "Qfit = np.polyfit(T_array, Q_array, 3)\n",
    "Q = np.poly1d(Qfit)\n",
    "\n",
    "x = np.array(detections[\"eup\"])\n",
    "y = lnnugu\n",
    "yerr = lnnugu_err.T\n",
    "\n",
    "lmfit_result = rotdiag_lmfit(x, y)    \n",
    "lmfit_T = lmfit_result.best_values[\"T\"]\n",
    "lmfit_log10Ntot = lmfit_result.best_values[\"log10Ntot\"]\n",
    "lmfit_tau = lmfit_result.best_values[\"tau\"]\n",
    "lmfit_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27681it [05:17, 87.31it/s, batch: 12 | bound: 92 | nc: 1 | ncall: 105840 | eff(%): 26.154 | loglstar:   -inf <  7.611 <  7.058 | logz: -0.124 +/-  0.143 | stop:  0.821]            \n"
     ]
    }
   ],
   "source": [
    "# log-likelihood\n",
    "def loglike(theta):\n",
    "    \n",
    "    T, log10Ntot, tau, lnf = theta\n",
    "    model = rotdiag(x,log10Ntot,T, tau)\n",
    "    inv_sigma2 = 1.0 / (yerr**2 + model**2 * np.exp(2 * lnf))\n",
    "    return -0.5 * (np.sum((y-model)**2 * inv_sigma2 - np.log(inv_sigma2)))\n",
    "\n",
    "# prior transform\n",
    "def prior_transform(utheta):\n",
    "    uT, ulog10Ntot, utau, ulnf = utheta\n",
    "    \n",
    "    log10Ntot = 5*ulog10Ntot + 8\n",
    "    # Truncated Normal\n",
    "    mean_T , s_T  = lmfit_T, 0.2*lmfit_T  # mean and standard deviation\n",
    "    low_T , high_T  = 0.5*lmfit_T, 1.5*lmfit_T\n",
    "    low_n_T, high_n_T = (low_T - mean_T ) / s_T , (high_T - s_T ) / s_T  # standardize\n",
    "    T = truncnorm.ppf(uT, low_n_T, high_n_T, loc=mean_T, scale=s_T)\n",
    "    # Truncated Normal\n",
    "    mean_log10Ntot , s_log10Ntot  = lmfit_log10Ntot, 0.2*lmfit_log10Ntot  # mean and standard deviation\n",
    "    low_log10Ntot , high_log10Ntot  = 0.5*lmfit_log10Ntot, 1.5*lmfit_log10Ntot\n",
    "    low_n_log10Ntot, high_n_log10Ntot = (low_log10Ntot - mean_log10Ntot ) / s_log10Ntot , (high_log10Ntot - s_log10Ntot ) / s_log10Ntot  # standardize\n",
    "    log10Ntot = truncnorm.ppf(ulog10Ntot, low_n_log10Ntot, high_n_log10Ntot, loc=mean_log10Ntot, scale=s_log10Ntot)\n",
    "    # Truncated Normal\n",
    "    mean_tau , s_tau  = lmfit_tau, 0.1*lmfit_tau  # mean and standard deviation\n",
    "    low_tau , high_tau  = 0.3*lmfit_tau, 1\n",
    "    low_n_tau, high_n_tau = (low_tau - mean_tau ) / s_tau , (high_tau - s_tau ) / s_tau  # standardize\n",
    "    tau = truncnorm.ppf(utau, low_n_tau, high_n_tau, loc=mean_tau, scale=s_tau)   \n",
    "    lnf = 21 * ulnf - 20.\n",
    "    return T, log10Ntot, tau, lnf\n",
    "\n",
    "dsampler = dynesty.DynamicNestedSampler(loglike, prior_transform, ndim=4, bound='multi', sample='auto')\n",
    "dsampler.run_nested(dlogz_init=0.01)\n",
    "rotdiag_res = dsampler.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sampling results.\n",
    "samples = rotdiag_res.samples  # samples\n",
    "weights = np.exp(rotdiag_res.logwt - rotdiag_res.logz[-1])  # normalized weights\n",
    "quantiles = [dyfunc.quantile(samps, [0.025, 0.1586, 0.5, 0.84135, 0.975], weights=weights)\n",
    "                 for samps in samples.T]\n",
    "\n",
    "labels = [r'T$_{rot}$ ', r'log$_{10}$(N$_{tot}$)',r'$\\tau$']\n",
    "fig, axes = dyplot.cornerplot(rotdiag_res, color='brown', show_titles=True, dims=[0,1,2],\n",
    "                              title_fmt=(\".4f\"), labels=labels, label_kwargs=dict({\"fontsize\":15}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a31bc3f60>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.errorbar(x,y,yerr=lnnugu_err.T, fmt=\"o\",color=\"black\",capsize=4)\n",
    "alphas = weights/max(weights)*0.1\n",
    "eulinspace = np.linspace(0,max(x)+10)\n",
    "for i,sample in enumerate(rotdiag_res.samples):\n",
    "    plt.plot(eulinspace, rotdiag(eulinspace, sample[1], sample[0], sample[2]),alpha=alphas[i],\n",
    "             color=\"dodgerblue\", linewidth=0.1)\n",
    "plt.plot(eulinspace, rotdiag(eulinspace,quantiles[1][2],quantiles[0][2],quantiles[2][2]),\n",
    "         color=\"black\",linestyle=\"--\",linewidth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./fits/{}_lines_dynesty\".format(molecule_name), line_results_dynesty)\n",
    "np.save(\"./fits/{}_lines_lmfit\".format(molecule_name), line_results_lmfit)\n",
    "np.save(\"./fits/{}_rotdiag_lmfit\".format(molecule_name), lmfit_result)\n",
    "np.save(\"./fits/{}_rotdiag_dynesty\".format(molecule_name), dres)\n",
    "np.save(\"./fits/{}_detection_info\".format(molecule_name), detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
