{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "---\n",
    "# SPOCK\n",
    "### Spectrum Parser for Organic Chemical Kinetics\n",
    "--- \n",
    "---\n",
    "v. 0.0.1 \n",
    "#### Written and updated by Carlos E. MuÃ±oz-Romero (2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sig\n",
    "import corner as corner\n",
    "import dynesty\n",
    "\n",
    "from lmfit import minimize, Parameters, fit_report, Model, Parameter\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## PART I\n",
    "### Emission Line Finder\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User inputs and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Molecule catalog\n",
    "molecule_name = \"CH3CN\"\n",
    "molecule_file = \"{}.txt\".format(molecule_name)\n",
    "spectrum_units = \"MHz\"\n",
    "database = \"JPL\"\n",
    "# Molecular dipole moment in cgs units\n",
    "mu = 3.9037 * 1e-18\n",
    "# Molecular partition function values to interpolate from\n",
    "Qrot = [13.8355, 28.4924, 64.0955, 164.3168, 449.0811, 1267.6705, 2628.0493]\n",
    "Trot = [2.725, 5.0, 9.375, 18.75, 37.5, 75.0, 120.0]\n",
    "# Assumed FWHM of emission lines in spectrum_units (0.5 km/s = 0.156355 MHz)\n",
    "line_width = 0.156355\n",
    "# Maximum distance from catalog frequency to consider a detection: \n",
    "line_error = line_width\n",
    "# Velocity of source in m/s\n",
    "v_lsr = 0#(-6.8+7.1)*1e3\n",
    "# Telescope data file\n",
    "spectrum_file = \"./181_WSW_FTS200_3mm_average_data_Tmb.dat\"\n",
    "# Root-mean-square error of intensity data\n",
    "rms = 5e-3\n",
    "# 1/2 size of fitting window around emission lines in spectrum_units\n",
    "window_size = 8\n",
    "# Constants\n",
    "c =  2.998*1e8 # speed of light in m/s\n",
    "k = 1.3807 * 1e-16  # Boltzmann constant in cgs units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data files and extract parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = np.loadtxt(spectrum_file)\n",
    "molecule_catalog = pd.read_csv(molecule_file, delimiter=\"\\t\", header=0, index_col=False)\n",
    "\n",
    "frequencies = spectrum[:,0]\n",
    "intensities = spectrum[:,1]\n",
    "\n",
    "molecule = dict({\"frequencies\":molecule_catalog[\"Frequency(Ghz)\"], \n",
    "                 \"intensities\":molecule_catalog[\"Intensity(K)\"],\n",
    "                 \"eup\":molecule_catalog[\"Eup(K)\"],\n",
    "                 \"aij\":molecule_catalog[\"Aij\"],\n",
    "                 \"transition\":molecule_catalog[\"Transition\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply redshift correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redshift(spectrum, velocity):\n",
    "    z = np.sqrt( (1 + (velocity/c)) / (1 - (velocity/c)) ) - 1\n",
    "    return spectrum/(1+z)\n",
    "\n",
    "frequencies = redshift(frequencies, v_lsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all peaks in the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = sig.find_peaks(intensities)[0]\n",
    "peak_intensities = intensities[peaks]\n",
    "peak_frequencies = frequencies[peaks]\n",
    "# Discriminate based on rms peak threshold\n",
    "peak_frequencies = peak_frequencies[peak_intensities>=5*rms]\n",
    "peak_intensities = peak_intensities[peak_intensities>=5*rms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify which peaks correspond to the molecular emission lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 transitions for CH3CN at \n",
      " [73588.7747, 73590.3372, 91985.2624, 91987.0202, 110381.359, 110383.508] MHz \n",
      "\n",
      "The corresponding catalog values for CH3CN are \n",
      " [73588.799, 73590.218, 91985.314, 91987.088, 110381.372, 110383.5] MHz \n",
      "\n",
      "Errors: \n",
      " [ 0.0243 -0.1192  0.0516  0.0678  0.013  -0.008 ] MHz \n",
      "\n"
     ]
    }
   ],
   "source": [
    "detection = dict({\"frequencies\":[], \n",
    "                  \"catalog_frequencies\":[],\n",
    "                  \"intensities\":[],\n",
    "                  \"eup\":[],\n",
    "                  \"aij\":[],\n",
    "                  \"transition\":[]})\n",
    "\n",
    "for i,peak_frequency in enumerate(peak_frequencies):\n",
    "    for j,molecule_frequency in enumerate(molecule[\"frequencies\"]):\n",
    "        if abs(peak_frequency-molecule_frequency)<=line_error:\n",
    "            detection[\"frequencies\"].append(peak_frequencies[i])\n",
    "            detection[\"catalog_frequencies\"].append(molecule[\"frequencies\"][j])\n",
    "            detection[\"intensities\"].append(peak_intensities[i])\n",
    "            detection[\"eup\"].append(molecule[\"eup\"][j])\n",
    "            detection[\"transition\"].append(molecule[\"transition\"][j])\n",
    "            \n",
    "n_detections = len(detection[\"frequencies\"])\n",
    "            \n",
    "print(\"Found {} transitions for {} at \\n {} {} \\n\".format(\n",
    "    n_detections, molecule_name, [round(x,5) for x in detection[\"frequencies\"]], spectrum_units))\n",
    "print(\"The corresponding catalog values for {} are \\n {} {} \\n\".format(\n",
    "    molecule_name, [round(x,5) for x in detection[\"catalog_frequencies\"]], spectrum_units))\n",
    "print(\"Errors: \\n {} {} \\n\".format(\n",
    "    np.array(detection[\"catalog_frequencies\"])-np.array(detection[\"frequencies\"]), spectrum_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## PART II\n",
    "### Line Profile Fitter\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a window around each line and identify the points that make up the line itself. Center the windows on zero to facilitate the fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "\n",
    "for det_frequency in detection[\"frequencies\"]:\n",
    "    window = dict({\"frequencies\":[],\n",
    "                   \"intensities\":[]})\n",
    "    f = frequencies[abs(frequencies-det_frequency)<window_size]\n",
    "    i = intensities[abs(frequencies-det_frequency)<window_size]\n",
    "    window[\"frequencies\"] = f-det_frequency\n",
    "    window[\"intensities\"] = i\n",
    "    windows.append(window)\n",
    "    \n",
    "\"LINE ID\"\n",
    "# Pick all monotonically decreasing neighbors of each detected line to fit.\n",
    "lines = []\n",
    "for i,window in enumerate(windows):\n",
    "    neighbors = dict({\"frequencies\":[],\n",
    "                      \"intensities\":[],\n",
    "                      \"indices\":[],\n",
    "                      \"line_idx\":0})\n",
    "    line_idx = np.where(window[\"frequencies\"]+detection[\"frequencies\"][i] == detection[\"frequencies\"][i])[0][0]\n",
    "    neighbors['line_idx'] = line_idx\n",
    "    # Left neighbors\n",
    "    diff = 0\n",
    "    i = 1\n",
    "    current = line_idx\n",
    "    while diff <= 0 and window[\"intensities\"][current-i] > -0.01 and abs(window[\"frequencies\"][current-i])<line_width*6:\n",
    "        current = line_idx-i\n",
    "        neighbors[\"frequencies\"].append(window[\"frequencies\"][current])\n",
    "        neighbors[\"intensities\"].append(window[\"intensities\"][current])\n",
    "        neighbors[\"indices\"].append(current)\n",
    "        diff = window[\"intensities\"][current-1]-window[\"intensities\"][current]\n",
    "        i+=1\n",
    "    # Right neighbors\n",
    "    diff = 0\n",
    "    i = 0\n",
    "    current = line_idx\n",
    "    while diff <= 0 and window[\"intensities\"][current+i] > -0.01 and abs(window[\"frequencies\"][current+i])<line_width*6:\n",
    "        current = line_idx+i\n",
    "        neighbors[\"frequencies\"].append(window[\"frequencies\"][current])\n",
    "        neighbors[\"intensities\"].append(window[\"intensities\"][current])\n",
    "        neighbors[\"indices\"].append(current)\n",
    "        diff = window[\"intensities\"][current+1]-window[\"intensities\"][current]\n",
    "        i+=1\n",
    "    lines.append(neighbors)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each detected emission line, fit a baseline polynomial via least squares and a Gaussian via dynamic nested sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"1-D GAUSSIAN\"\n",
    "def gaussian(x, amp, wid):\n",
    "    return (amp / (np.sqrt(2*np.pi) * wid)) * np.exp(-(x)**2 / (2*wid**2))\n",
    "\"LINE MODEL\"\n",
    "def line_model(x, amp, wid):\n",
    "    return gaussian(x, amp, wid)\n",
    "\n",
    "\"LOG LIKELIHOOD\"\n",
    "def loglike(theta):\n",
    "    amp, wid, lnf = theta\n",
    "    model = line_model(x, amp, wid)\n",
    "    inv_sigma2 = 1.0 / (yerr**2 + model**2 * np.exp(2 * lnf))\n",
    "    \n",
    "    return -0.5 * (np.sum((y-model)**2 * inv_sigma2 - np.log(inv_sigma2)))\n",
    "\n",
    "\"PRIORS\"\n",
    "def prior_transform(utheta):\n",
    "    uamp, uwid, ulf = utheta\n",
    "    amp = uamp*guess*3\n",
    "    wid = 3*line_width*uwid + 0.05\n",
    "    lnf = 11. * ulf - 10.\n",
    "    return amp, wid, lnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113it [00:00, 380.67it/s, batch: 0 | bound: 0 | nc: 2 | ncall: 131 | eff(%): 17.908 | loglstar:   -inf < -894.295 <    inf | logz: -901.425 +/-  0.169 | dlogz: 918.385 >  0.000] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting line 1 of 6 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10279it [03:18,  3.52it/s, batch: 5 | bound: 0 | nc: 1 | ncall: 70076 | eff(%): 14.668 | loglstar:  7.120 < 11.372 <  7.631 | logz:  7.769 +/-  0.109 | stop:    nan]             \n",
      "56it [00:00, 558.74it/s, batch: 0 | bound: 0 | nc: 1 | ncall: 62 | eff(%):  9.964 | loglstar:   -inf < -2123.026 <    inf | logz: -2130.045 +/-  0.167 | dlogz: 2169.069 >  0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting line 2 of 6 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9517it [01:16, 29.56it/s, batch: 2 | bound: 28 | nc: 2 | ncall: 38415 | eff(%): 24.759 | loglstar: 19.997 < 22.411 < 20.441 | logz: 17.224 +/-  0.123 | stop:  2.049]               "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "baselines = []\n",
    "fitlinesy = []\n",
    "fitlinesx = []\n",
    "\n",
    "for i,window in enumerate(windows):\n",
    "    print(\"Fitting line {} of {} \\n\".format(i+1, n_detections))\n",
    "    line_indices = np.zeros(len(window[\"frequencies\"]))\n",
    "    line_indices[lines[i][\"indices\"]] = 1\n",
    "    x = window[\"frequencies\"]\n",
    "    y = window[\"intensities\"]\n",
    "\n",
    "    nonline_frequecies = x[line_indices==0]\n",
    "    nonline_intensities = y[line_indices==0]\n",
    "    \n",
    "    baseline_frequecies  = nonline_frequecies[abs(nonline_intensities)<rms*2]\n",
    "    baseline_intensities = nonline_intensities[abs(nonline_intensities)<rms*2]\n",
    "    baseline_fit = np.polyfit(baseline_frequecies, baseline_intensities, 2)\n",
    "    baseline = np.poly1d(baseline_fit)\n",
    "    y = y-baseline(x)\n",
    "    \n",
    "    x = x[line_indices==1]\n",
    "    y = y[line_indices==1]\n",
    "    \n",
    "    guess = max(y)*np.sqrt(2*np.pi)*line_width\n",
    "    \n",
    "    y = np.array([k if k>0 else 0 for k in y])\n",
    "    yerr = np.array([1e-3 for i in y])\n",
    "    \n",
    "    fitlinesy.append(y)\n",
    "    fitlinesx.append(x)\n",
    "    dsampler = dynesty.DynamicNestedSampler(loglike, prior_transform, ndim=3,\n",
    "                                            bound='multi', sample='auto')\n",
    "    dsampler.run_nested(dlogz_init=0.0001, maxiter=10000)\n",
    "    results.append(dsampler.results)\n",
    "    baselines.append(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize fits and convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import plotting as dyplot\n",
    "labels = [\"FLUX\", \"LINE WIDTH\", \"ERROR MULTIPLIER\"]\n",
    "\n",
    "for i,res in enumerate(results):\n",
    "    #fig, axes = dyplot.traceplot(res, labels=labels)\n",
    "    plt.figure()\n",
    "    window_linspace = np.linspace(min(windows[i][\"frequencies\"]), max(windows[i][\"frequencies\"]),10000)\n",
    "    \n",
    "    best_amp = np.median(res.samples[:,0])\n",
    "    best_wid = np.median(res.samples[:,1])\n",
    "    lnf = np.median(res.samples[:,2])\n",
    "    \n",
    "    plt.step(windows[i][\"frequencies\"], windows[i][\"intensities\"])\n",
    "    plt.step(windows[i][\"frequencies\"], windows[i][\"intensities\"]-baselines[i](window[\"frequencies\"]))\n",
    "    \n",
    "    for sample in res.samples[::20]:\n",
    "        gauss = gaussian(window_linspace, sample[0], sample[1])\n",
    "        plt.plot(window_linspace, gauss, linestyle='-', color=\"lime\", label='best fit', linewidth=0.05, alpha=0.2)\n",
    "    \n",
    "    gauss = gaussian(window_linspace, best_amp, best_wid)\n",
    "    plt.plot(window_linspace, gauss, linestyle='--', color=\"green\", label='best fit', linewidth=3)\n",
    "    plt.plot(window_linspace, baselines[i](window_linspace), linestyle='--', color=\"black\", label='best fit', linewidth=3)\n",
    "    plt.scatter(fitlinesx[i], fitlinesy[i], color=\"red\", linewidth=5, alpha=0.4)\n",
    "    plt.title(\"TRANSITION AT {} {}\".format(detection[\"frequencies\"][i], spectrum_units))\n",
    "    plt.ylim(min(windows[i][\"intensities\"]),gaussian(0, best_amp, best_wid)+gaussian(0, best_amp, best_wid)*1.1)\n",
    "    \n",
    "    plt.xlabel(\"[{}]\".format(spectrum_units), fontsize=15)\n",
    "    plt.ylabel(\"Intensity [K]\", fontsize=15)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,res in enumerate(results):\n",
    "    fig, axes = dyplot.traceplot(res, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n BEST FIT FLUXES \\n\")\n",
    "for i,res in enumerate(results):\n",
    "    flux = round(np.median(res.samples[:,0])*0.5/line_width,5)\n",
    "    fluxstd = round(np.std(res.samples[:,0])*0.5/line_width,5)\n",
    "    print(\"{} +- {} K.km/s\".format(flux, fluxstd))\n",
    "    \n",
    "print(\"\\n BEST FIT LINE WIDTHS \\n\")\n",
    "for i,res in enumerate(results):\n",
    "    wid = round(np.median(res.samples[:,1])*0.5/line_width,5)\n",
    "    widstd = round(np.std(res.samples[:,1])*0.5/line_width,5)\n",
    "    print(\"{} +- {} km/s\".format(wid, widstd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## PART III\n",
    "### Rotation Diagrams\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the transition numbers to look up the line strengths (sorry, gotta do it manually)\n",
    "strength = np.array([79.48062, 84.80078, 101.74150, 105.98313, 123.64362, 127.17758])/((mu*1e18)**2)\n",
    "# Save fluxes in cm/s\n",
    "fluxes = dict({\"values\":np.array([np.median(res.samples[:,0]) for res in results])*0.5/line_width*100000,\n",
    "               \"errors\":np.array([np.std(res.samples[:,0]) for res in results])*0.5/line_width*100000})\n",
    "# Convert line widths to km/s\n",
    "widths = dict({\"values\":np.array([np.median(res.samples[:,1]) for res in results])*0.5/0.156355,\n",
    "               \"errors\":np.array([np.std(res.samples[:,1]) for res in results])*0.5/0.156355})\n",
    "toHz = 1e6\n",
    "detection[\"frequencies\"] = np.array(detection[\"frequencies\"])\n",
    "detection[\"eup\"] = np.array(detection[\"eup\"])\n",
    "# Upper-level populations Nu/gu\n",
    "lnnugu = np.log((3*k*fluxes[\"values\"])/(8*(np.pi**3)*detection[\"frequencies\"]*toHz*(mu**2)*strength))\n",
    "\n",
    "nugu_err = ((3*k*fluxes[\"errors\"])/(8*(np.pi**3)*detection[\"frequencies\"]*toHz*(mu**2)*strength))\n",
    "lnnugu_err = nugu_err / np.exp(lnnugu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate rotation diagram via dynamic nested sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = detection[\"eup\"]\n",
    "y = lnnugu\n",
    "yerr = lnnugu_err\n",
    "\n",
    "# log-likelihood\n",
    "def loglike(theta):\n",
    "    m, intrcpt, lnf = theta\n",
    "    model = intrcpt + m*x\n",
    "    inv_sigma2 = 1.0 / (yerr**2 + model**2 * np.exp(2 * lnf))\n",
    "    \n",
    "    return -0.5 * (np.sum((y-model)**2 * inv_sigma2 - np.log(inv_sigma2)))\n",
    "\n",
    "# prior transform\n",
    "def prior_transform(utheta):\n",
    "    um, uintrcpt, ulnf = utheta\n",
    "    m = -0.5*um - 0.03 \n",
    "    intrcpt = 3 * uintrcpt + 20 \n",
    "    lnf = 11. * ulnf - 10.\n",
    "    \n",
    "    return m, intrcpt, lnf\n",
    "\n",
    "dsampler = dynesty.DynamicNestedSampler(loglike, prior_transform, ndim=3, bound='multi', sample='auto')\n",
    "dsampler.run_nested(dlogz_init=0.00001, maxiter=10000)\n",
    "dres = dsampler.results\n",
    "labels = [r'$-1/T$', r'$\\ln(N_u/g_u)[E_u=0]$', r'$\\ln f$']\n",
    "fig, axes = dyplot.traceplot(dres, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trot = dict({\"value\":-1/np.median(dres.samples[:,0]),\n",
    "             \"error\": np.std(1/dres.samples[:,0])})\n",
    "\n",
    "lnNugu_0 = dict({\"value\":np.median(dres.samples[:,1]),\n",
    "                 \"error\":np.std(dres.samples[:,1])})\n",
    "\n",
    "print(\"BEST FIT ROTATIONAL TEMPERATURE: {} +- {} K\\n\".format(round(Trot[\"value\"],4), round(Trot[\"error\"],4)))\n",
    "print(\"BEST FIT INTERCEPT: {} +- {} \\n\".format(round(lnNugu_0[\"value\"],4), round(lnNugu_0[\"error\"],4)))\n",
    "\n",
    "Eu_linspace = np.linspace(0, max(detection[\"eup\"])+5, 1000)\n",
    "\n",
    "def rotdiag_model(Eu, m, lnNugu):\n",
    "    return lnNugu + m*Eu\n",
    "\n",
    "plt.scatter(detection[\"eup\"] , lnnugu, c=\"purple\")\n",
    "\n",
    "plt.errorbar(detection[\"eup\"] , lnnugu, yerr=yerr, capsize=5, c=\"purple\", fmt=\"none\")\n",
    "\n",
    "for sample in dres.samples[::10]:\n",
    "    plt.plot(Eu_linspace, rotdiag_model(Eu_linspace, sample[0], sample[1]), color=\"lime\", linewidth=0.05, alpha=0.2)    \n",
    "\n",
    "plt.plot(Eu_linspace, rotdiag_model(Eu_linspace, np.median(dres.samples[:,0]), lnNugu_0[\"value\"]), color=\"red\", linewidth=1, alpha=1)    \n",
    "plt.ylabel(\"$\\ln(N_u/g_u)$\", fontsize=15)\n",
    "plt.xlabel(\"$E_u/k$\", fontsize=15)\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
